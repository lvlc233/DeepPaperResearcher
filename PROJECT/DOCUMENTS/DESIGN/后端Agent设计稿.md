# Agent设计稿
from: 管理员
create_time: 2026-01-07

## AI搜索模块
### 介绍
该Agent模块负责根据用户输入的问题，在本地数据库和网络上搜索相关信息，并根据搜索的结果对相关性进行排名，并给出搜索推荐理由。
### 使用场景
1. 搜索输入框
### 节点
1. 初始化节点:
    - 负责加载加载基础数据相关:例如用户记忆(操作习惯，映射词表)等概念。
    - 暂时使用dict表示承载内容，随项目进度逐步完善。
    - 输入: 用户query,用户id。
    - 输出: 后续节点可能需要的数据的配置字典。
2. RAG节点:
    - 负责根据用户输入的问题，在本地数据库和网络上搜索相关信息。
    - 使用RAG(向量+混合搜索)技术搜索本地的数据。
    - 输入: 一组输入(初始query,推理节点反推的query，过滤条件组),用户id,
    - 输出: 一组带有id的原始论文数据
3. 网络搜索节点:
    - 负责根据用户输入的问题，在网络上搜索相关信息。
    - 配置: 网络搜索的参数，例如搜索深度，搜索时间等。
    - 输入: 一组关键词,可检索配置参数。
    - 输出: 一组带有原始url路径的论文数据
4. 推理节点:
    - 对检索到的内容进行排除或排序加载排序。进行理解操作
    - 基于结构化输出处理数据。
    - 输入: 当前任务状态(初始化,执行情况,执行计划),用户id,检索到的论文数据,上下文记忆
    - 输出: 下一组任务状态(执行计划,下一组检索条件(过滤条件组)),论文的处理结果(移除或保存留)
5. 结束判断路由:
    - 根据设置的约束条件进行判断，判断是否需要继续搜索或结束。
    - 基于工具调度。
6. 存储节点:
    - 存储每次检索的key和cache
    - 用于提高资源复用率,使用缓存机制
    - 输入: 一组搜索记录,用户id,用户query,
    - 输出: 无
### 控制编排
1. init_node
2. init->rag_node
3. init->web_search_node
4. (rag_node,web_search_node)->chat_node
5. chat->router->Tool?(rag_node,web_search_node)
6. char->router->store->End
7. Tool?(rag_node,web_search_node)->chat_node


## 论文内容总结
### 介绍
总结当前论文并生成摘要。并持久化
### 使用场景
1. 论文助手加载
### 节点
1. 初始化节点:
    - 负责加载加载基础数据相关:例如用户记忆(操作习惯，映射词表)等概念。
    - 使用Typedict表示承载内容，随项目进度逐步完善。
    - 输入: 可以配置参数(当前论文id,是否加载视图),用户id。
    - 输出: 后续节点可能需要的数据的配置字典。
2. 上下文转化节点:
    - 负责获取当前论文的信息并将其转化为更好的上下文数据(提示词引导,表转换，数学符号重整理)
    - 输入: 论文id,视图数据
    - 输出: 一组被重新转换的上下文信息
3. 推理节点:
    - 负责根据拿到的上下文进行总结
    - 输入: 论文上下文,用户query
    - 输出: 带有id的摘要信息。
4. 持久化节点
    - 负责将摘要持久化
    - 输入: 摘要信息,论文id,用户id
    - 输出: 无
### 控制编排
1. init->context_trans
2. context_trans->chat
3. chat->store->end


## 论文内容脑图生成
### 介绍
总结当前论文并生成脑图。并持久化
### 使用场景
1. 论文助手加载
### 节点
1. 初始化节点:
    - 负责加载加载基础数据相关:例如用户记忆(操作习惯，映射词表)等概念。
    - 暂时使用dict表示承载内容，随项目进度逐步完善。
    - 输入: 可以配置参数(当前论文id,是否加载视图),用户id。
    - 输出: 后续节点可能需要的数据的配置字典。
2. 上下文转化节点:
    - 负责获取当前论文的信息并将其转化为更好的上下文数据(提示词引导,表转换，数学符号重整理)
    - 输入: 论文id,视图数据
    - 输出: 一组被重新转换的上下文信息
3. 推理节点:
    - 负责根据拿到的上下文进行总结
    - 输入: 论文上下文,用户query
    - 输出: 带有id的脑图信息。
4. 持久化节点
    - 负责将脑图持久化
    - 输入: 脑图信息,论文id,用户id
    - 输出: 无
### 控制编排
1. init->context_trans
2. context_trans->chat
3. chat->store->end

### 论文内对话节点
1. 初始化节点:
    - 负责加载加载基础数据相关:例如用户记忆(操作习惯，映射词表)等概念。
    - 暂时使用dict表示承载内容，随项目进度逐步完善。
    - 输入: 用户query,用户id。
    - 输出: 后续节点可能需要的数据的配置字典。
2. RAG节点:
    - 负责根据用户输入的问题，在本地数据库和网络上搜索相关信息。
    - 使用RAG(向量+混合搜索)技术搜索本地的数据。
    - 输入: 一组输入(初始query,推理节点反推的query，过滤条件组),用户id,
    - 输出: 一组带有id的原始论文数据
3. 网络搜索节点:
    - 负责根据用户输入的问题，在网络上搜索相关信息。
    - 配置: 网络搜索的参数，例如搜索深度，搜索时间等。
    - 输入: 一组关键词,可检索配置参数。
    - 输出: 一组带有原始url路径的论文数据
4. 推理节点:
    - 对检索到的论文理解操作,并对query进行回答
    - 一边输出，一便理解概念
    - 输入: 当前任务状态的理解情况(用户需求,工具需求),用户id,检索到的论文数据,上下文记忆
    - 输出: 下一组任务状态(执行计划,下一组检索条件(过滤条件组)),论文的处理结果(标记有效和无效数据,并建立检索表和相关词表)
5. 结束判断路由:
    - 根据设置的约束条件进行判断，判断是否需要继续搜索或结束。
    - 基于工具调度。

### 控制编排
1. init_node
2. init_node->chat_node
3. chat->router->Tool?(rag_node,web_search_node)
4. char->router->End
5. Tool?(rag_node,web_search_node)->chat_node

## 深度研究Agent
### 介绍
负责执行深度研究任务，生成长篇报告。
### 核心逻辑
1. **任务分解**: 将用户的大问题分解为多个子问题。
2. **迭代检索**: 针对每个子问题进行多轮检索 (Web/Local)。
3. **信息综合**: 汇总检索结果，生成中间摘要。
4. **报告生成**: 最终合成完整报告。

## Agent 统一接口适配 (SSE Adapter)
为了满足前端 `Unified Chat Service` 的需求，所有 Agent 的输出需通过适配器转换为 SSE 事件流。

### 事件映射
- **思考过程 (CoT)** -> `token` (或内部日志，视配置而定)
- **工具调用** -> `tool_call` (包含 `tool_name`, `args`)
- **工具结果** -> `tool_result`
- **文本输出** -> `token`
- **引用来源** -> `citation` (在 RAG 节点或推理节点输出时附带)
- **异常** -> `error`
- **结束** -> `finish`
